# -*- coding: utf-8 -*-
"""Stochastic_GD.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GbiPiHc9XbmEQYsC4yMyrso5ok6p1DCs

# Stochastic Gradient Descent
"""

from sklearn.datasets import load_diabetes
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
from sklearn.model_selection import train_test_split

X, y = load_diabetes(return_X_y=True)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)

reg = LinearRegression()
reg.fit(X_train, y_train)

print(reg.coef_)
print(reg.intercept_)

y_pred = reg.predict(X_test)
r2_score(y_test, y_pred)


class SGDRegressor:
    def __init__(self, learning_rate=0.01, epochs=100):
        self.coef_ = None
        self.intercept_ = None
        self.lr = learning_rate
        self.epochs = epochs

    def fit(self, X_train, y_train):
        # init ur coefficients
        self.intercept_ = 0  # b0
        # all the coefficients will be equal to the number of cols
        # self.coef_ is an array
        self.coef_ = np.ones(X_train.shape[1])

        for i in range(self.epochs):
            # X_train.shape[1] is the # of features/cols : we do this
            #  b/c we have to calculate for b0,b1,b2,b3....
            for j in range(X_train.shape[1]):
                idx = np.random.randint(0, X_train.shape[0])
                # we will extract idxth row
                # y hat is scalar now
                y_hat = np.dot(X_train[idx], self.coef_) + self.intercept_
                intercept_derivative = -2 * (y_train[idx] - y_hat)
                self.intercept_ = self.intercept_ - (self.lr * intercept_derivative)

                coef_derivative = -2 * np.dot((y_train[idx] - y_hat), X_train[idx])
                self.coef_ = self.coef_ - (self.lr * coef_derivative)

        print(self.intercept_, self.coef_)

    def predict(self, X_test):
        return np.dot(X_test, self.coef_) + self.intercept_


sgdr = SGDRegressor(learning_rate=0.68, epochs=1500)

sgdr.fit(X_train, y_train)

y_pred = sgdr.predict(X_test)

r2_score(y_test, y_pred)

# time stamp : 24:13 -> Video : Stochastic Gradient
